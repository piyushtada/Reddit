{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To dos:\n",
    "- [x] Write SQL to collect data\n",
    "- [ ] Create a function that do sentiment analysis on a sentence\n",
    "- [ ] Apply the function on all the dataset\n",
    "- [ ] Visulaize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.mymodule.database import sql_to_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \\\n",
    "\"\"\"\n",
    "SELECT DISTINCT DATE_TRUNC('month', comment_date) AS month\n",
    "FROM l0_comments_filtered_dates;\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-02-01 00:00:00+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-03-01 00:00:00+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-01 00:00:00+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-05-01 00:00:00+02:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       month\n",
       "0  2018-01-01 00:00:00+01:00\n",
       "1  2018-02-01 00:00:00+01:00\n",
       "2  2018-03-01 00:00:00+01:00\n",
       "3  2018-04-01 00:00:00+02:00\n",
       "4  2018-05-01 00:00:00+02:00"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sql_to_pandas(query)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the months inside total data\n",
    "date_list = [str(dt.date())[:10] for dt in df.month.to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2018-01-01', '2018-02-01', '2018-03-01', '2018-04-01', '2018-05-01']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_list[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_month = '2018-01-01'\n",
    "month_data_sql = \\\n",
    "f\"\"\"\n",
    "SELECT author, STRING_AGG(clean_text, ' ') AS comments\n",
    "FROM l0_comments_filtered_dates \n",
    "WHERE date_trunc('month', comment_date) = '{date_month}'\n",
    "GROUP BY author;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nrclex import NRCLex\n",
    "def _NRCL_affect_lexicon(text):\n",
    "    # NRCLex\n",
    "    text_object = NRCLex(text)\n",
    "\n",
    "    return text_object.affect_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'no no those are behind us preventing us from walking off the guy that chose to is about to get shot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "something = _NRCL_affect_lexicon(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fear': 0.2,\n",
       " 'anger': 0.2,\n",
       " 'anticip': 0.0,\n",
       " 'trust': 0.0,\n",
       " 'surprise': 0.2,\n",
       " 'positive': 0.0,\n",
       " 'negative': 0.2,\n",
       " 'sadness': 0.2,\n",
       " 'disgust': 0.0,\n",
       " 'joy': 0.0}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/piyush/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/piyush/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/piyush/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive score: 0.0\n",
      "Negative score: 0.234\n",
      "Neutral score: 0.766\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Download necessary NLTK packages\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Sample text\n",
    "# text = \"I love the beach. The ocean is so blue and the sand is warm.\"\n",
    "\n",
    "# Tokenize the text\n",
    "tokens = nltk.word_tokenize(text)\n",
    "\n",
    "# Perform part-of-speech tagging\n",
    "pos_tags = nltk.pos_tag(tokens)\n",
    "\n",
    "# Perform sentiment analysis\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "sentiment_scores = sia.polarity_scores(text)\n",
    "\n",
    "# Calculate emotion scores\n",
    "positive_score = sentiment_scores['pos']\n",
    "negative_score = sentiment_scores['neg']\n",
    "neutral_score = sentiment_scores['neu']\n",
    "\n",
    "print('Positive score:', positive_score)\n",
    "print('Negative score:', negative_score)\n",
    "print('Neutral score:', neutral_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the DataFrame to a CSV file\n",
    "df.to_csv('./data/my_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the DataFrame to a CSV file\n",
    "df.to_csv('./data/my_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.234, 'neu': 0.766, 'pos': 0.0, 'compound': -0.5423}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('no', 'DT'),\n",
       " ('no', 'DT'),\n",
       " ('those', 'DT'),\n",
       " ('are', 'VBP'),\n",
       " ('behind', 'IN'),\n",
       " ('us', 'PRP'),\n",
       " ('preventing', 'VBG'),\n",
       " ('us', 'PRP'),\n",
       " ('from', 'IN'),\n",
       " ('walking', 'VBG'),\n",
       " ('off', 'RP'),\n",
       " ('the', 'DT'),\n",
       " ('guy', 'NN'),\n",
       " ('that', 'WDT'),\n",
       " ('chose', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('is', 'VBZ'),\n",
       " ('about', 'IN'),\n",
       " ('to', 'TO'),\n",
       " ('get', 'VB'),\n",
       " ('shot', 'JJ')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/piyush/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Lemmatize words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    # Join tokens back into a string\n",
    "    text = ' '.join(tokens)\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = preprocess_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'behind u preventing u walking guy chose get shot'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "something = _NRCL_affect_lexicon(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fear': 0.2,\n",
       " 'anger': 0.2,\n",
       " 'anticip': 0.0,\n",
       " 'trust': 0.0,\n",
       " 'surprise': 0.2,\n",
       " 'positive': 0.0,\n",
       " 'negative': 0.2,\n",
       " 'sadness': 0.2,\n",
       " 'disgust': 0.0,\n",
       " 'joy': 0.0}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _tmp = {'Id': nodes, 'avg_word_count': word_count, 'avg_unique_words': unique_words_cnt,\n",
    "#                     'avg_lexical_diversity': lexical_diversity, 'avg_vader_positive': vader_positive,\n",
    "#                     'avg_vader_negative': vader_negative, 'avg_vader_neutral': vader_neutral,\n",
    "#                     'avg_vader_compound': vader_compound, 'avg_textblob_polarity': textblob_polarity,\n",
    "#                     'avg_textblob_subjectivity': textblob_subjectivity,\n",
    "#                     'avg_NRCL_positive': NRCL_positive, 'avg_NRCL_negative': NRCL_negative,\n",
    "#                     'avg_NRCL_anticipation': NRCL_anticipation, 'avg_NRCL_surprise': NRCL_surprise,\n",
    "#                     'avg_NRCL_trust': NRCL_trust, 'avg_NRCL_joy': NRCL_joy, 'avg_NRCL_fear': NRCL_fear,\n",
    "#                     'avg_NRCL_anger': NRCL_anger, 'avg_NRCL_sadness': NRCL_sadness,\n",
    "#                     'avg_NRCL_disgust': NRCL_disgust, 'avg_VAD_arousal': VAD_arousal,\n",
    "#                     'avg_VAD_dominance': VAD_dominance, 'avg_VAD_valence': VAD_valence,\n",
    "#                     'avg_taboo_rate': taboo_rate,\n",
    "#                     'cnt_LNA_Foot_leg': LNA_footleg, 'cnt_LNA_Hand_arm': LNA_handarm, 'cnt_LNA_Head': LNA_head,\n",
    "#                     'cnt_LNA_Mouth': LNA_mouth, 'cnt_LNA_Torso': LNA_torso, 'cnt_LNP_Auditory': LNP_auditory,\n",
    "#                     'cnt_LNP_Gustatory': LNP_gustatory, 'cnt_LNP_Haptic': LNP_haptic,\n",
    "#                     'cnt_LNP_Interoceptive': LNP_interoceptive, 'cnt_LNP_Olfactory': LNP_olfactory,\n",
    "#                     'cnt_LNP_Visual': LNP_visual}\n",
    "# node_labels = pd.DataFrame(_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/piyush/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/piyush/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/piyush/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "def get_sentiment_scores(text):\n",
    "    # Tokenize the text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # Perform part-of-speech tagging\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "\n",
    "    # Perform sentiment analysis\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    sentiment_scores = sia.polarity_scores(text)\n",
    "\n",
    "    # Calculate emotion scores\n",
    "    positive_score = sentiment_scores['pos']\n",
    "    negative_score = sentiment_scores['neg']\n",
    "    neutral_score = sentiment_scores['neu']\n",
    "\n",
    "    return positive_score, negative_score, neutral_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
